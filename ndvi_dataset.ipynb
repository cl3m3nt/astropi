{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('astropi': conda)",
   "metadata": {
    "interpreter": {
     "hash": "52fb03e2644f45c6d5ab757b34b7c4ef6f5c61b726ac7e10d580b0b3db2a5f61"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pre-requesite\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input,Conv2D, MaxPool2D, GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.applications import MobileNetV2, EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get CWD\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Data\n",
    "base_path = os.getcwd() + '/Dataset'\n",
    "image_list = os.listdir('./Dataset')\n",
    "image0_path = os.path.join(base_path,image_list[0])\n",
    "image0 = Image.open(image0_path)\n",
    "plt.imshow(image0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrast_stretch(im):\n",
    "    \"\"\"\n",
    "    Performs a simple contrast stretch of the given image, from 5-100%.\n",
    "    \"\"\"\n",
    "    in_min = np.percentile(im, 5)\n",
    "    in_max = np.percentile(im, 100)\n",
    "\n",
    "    out_min = 0.0\n",
    "    out_max = 255.0\n",
    "\n",
    "    out = im - in_min\n",
    "    out *= ((out_min - out_max) / (in_min - in_max))\n",
    "    out += in_min\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def get_ndvi(image_path):\n",
    "    \"\"\"\n",
    "    Transform a raw image to ndvi image\n",
    "    \"\"\"\n",
    "    image = cv2.imread(image_path) \n",
    "    b, g, r = cv2.split(image)\n",
    "\n",
    "    bottom = (r.astype(float) + b.astype(float))\n",
    "    bottom[bottom == 0] = 0.00001  # Make sure we don't divide by zero!\n",
    "    ndvi_image = (r.astype(float) - b) / bottom\n",
    "    ndvi_image = contrast_stretch(ndvi_image)\n",
    "    ndvi_image = ndvi_image.astype(np.uint8)\n",
    "    return ndvi_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi0 = get_ndvi(image0_path)\n",
    "ndvi0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ndvi0)\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "#  NDVI / NO2 Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get NDVI images\n",
    "def ndvi_images():\n",
    "    ndvi_img_list = []\n",
    "    for i in range(0,len(image_list)):\n",
    "        img_path = os.path.join(base_path,image_list[i])\n",
    "        ndvi_img = get_ndvi(img_path)\n",
    "        ndvi_img_list.append(ndvi_img)\n",
    "    ndvi_img_numpy = np.array(ndvi_img_list)\n",
    "    return ndvi_img_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get NO2 label within [0,2]\n",
    "def no2_labels():\n",
    "    label_list = []\n",
    "    for i in range(0,82):\n",
    "        random_label = random.randint(0,2)\n",
    "        label_list.append(random_label)\n",
    "    label_numpy = np.array(label_list)\n",
    "    return label_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Info on X and Y\n",
    "print(ndvi_img_numpy.shape)\n",
    "print(label_numpy.shape)"
   ]
  },
  {
   "source": [
    "# Modeling Conv1D"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    tf.keras.layers.Conv1D(8,(3),input_shape=(1944,2592)),\n",
    "    tf.keras.layers.MaxPool1D(2,2),\n",
    "    tf.keras.layers.Conv1D(16,(3)),\n",
    "    tf.keras.layers.MaxPool1D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(3,activation='softmax')\n",
    "])\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = ndvi_img_numpy\n",
    "y_train = label_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train,y_train,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "x = PrettyTable()\n",
    "x.field_names = [\"City name\", \"Area\", \"Population\", \"Annual Rainfall\"]\n",
    "x.add_row([\"Adelaide\", 1295, 1158259, 600.5])\n",
    "x.add_row([\"Brisbane\", 5905, 1857594, 1146.4])\n",
    "x.add_row([\"Darwin\", 112, 120900, 1714.7])\n",
    "x.add_row([\"Hobart\", 1357, 205556, 619.5])\n",
    "x.add_row([\"Sydney\", 2058, 4336374, 1214.8])\n",
    "x.add_row([\"Melbourne\", 1566, 3806092, 646.9])\n",
    "x.add_row([\"Perth\", 5386, 1554769, 869.4])\n",
    "print(x)"
   ]
  },
  {
   "source": [
    "# Modeling Conv2D"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pythonexamples.org/python-opencv-cv2-resize-image/\n",
    "\n",
    "def scale_down(image):\n",
    "    src = image\n",
    "    #percent by which the image is resized\n",
    "    scale_percent = 25\n",
    "\n",
    "    #calculate the 50 percent of original dimensions\n",
    "    width = int(src.shape[1] * scale_percent / 100)\n",
    "    height = int(src.shape[0] * scale_percent / 100)\n",
    "\n",
    "    # dsize\n",
    "    dsize = (width, height)\n",
    "\n",
    "    # resize image\n",
    "    output = cv2.resize(src, dsize)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_img_list = []\n",
    "for i in range(0,len(image_list)):\n",
    "    img_path = os.path.join(base_path,image_list[i])\n",
    "    ndvi_img = get_ndvi(img_path)\n",
    "    ndvi_img = scale_down(ndvi_img)\n",
    "    ndvi_img_list.append(ndvi_img)\n",
    "ndvi_img_numpy = np.array(ndvi_img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = ndvi_img_numpy\n",
    "y_train = label_numpy\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.expand_dims(x_train,axis=3)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    tf.keras.layers.Conv2D(8,(3,3),input_shape=(486,648,1)),\n",
    "    tf.keras.layers.MaxPool2D(2,2),\n",
    "    tf.keras.layers.Conv2D(16,(3,3)),\n",
    "    tf.keras.layers.MaxPool2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(3,activation='softmax')\n",
    "])\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train,y_train,epochs=10)"
   ]
  },
  {
   "source": [
    "# Modeling MobileNetV2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi2rgb = cv2.cvtColor(ndvi0,cv2.COLOR_GRAY2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi2rgb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = ndvi_img_numpy\n",
    "y_train = label_numpy\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain2rgb = cv2.cvtColor(x_train,cv2.COLOR_GRAY2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ndvi_img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_rgb_list = []\n",
    "for i in range(0,len(ndvi_img_list)):\n",
    "    ndvi_rgb = cv2.cvtColor(ndvi_img_list[i],cv2.COLOR_GRAY2RGB)\n",
    "    ndvi_rgb_list.append(ndvi_rgb)\n",
    "ndvi_rgb_numpy = np.array(ndvi_rgb_list)\n",
    "print(ndvi_rgb_numpy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = ndvi_rgb_numpy\n",
    "y_train = label_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenetv2 = MobileNetV2(include_top=False, weights='imagenet',input_shape=(486,648,3))\n",
    "for layer in mobilenetv2.layers:\n",
    "        layer.trainable = False\n",
    "mobilenetv2_preprocess = tf.keras.applications.mobilenet_v2.preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "mobilenetv2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer Learning\n",
    "input_shape = (486,648,3)\n",
    "img_in = Input(shape=input_shape, name='img_in')\n",
    "x = mobilenetv2_preprocess(img_in)\n",
    "x = mobilenetv2(img_in, training=True)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# Classification layer\n",
    "output = Dense(3, activation='softmax', name='dense')(x)\n",
    "# Final model\n",
    "model = Model(inputs=[img_in], outputs=output)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train,y_train,epochs=10)"
   ]
  },
  {
   "source": [
    "# Modeling EfficientNetB0"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_rgb_list = []\n",
    "for i in range(0,len(ndvi_img_list)):\n",
    "    ndvi_rgb = cv2.cvtColor(ndvi_img_list[i],cv2.COLOR_GRAY2RGB)\n",
    "    ndvi_rgb_list.append(ndvi_rgb)\n",
    "ndvi_rgb_numpy = np.array(ndvi_rgb_list)\n",
    "print(ndvi_rgb_numpy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = ndvi_rgb_numpy\n",
    "y_train = label_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnetb0 = EfficientNetB0(include_top=False, weights='imagenet',input_shape=(486,648,3))\n",
    "for layer in efficientnetb0.layers:\n",
    "        layer.trainable = False\n",
    "efficientnetb0_preprocess = tf.keras.applications.efficientnet.preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "efficientnetb0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer Learning\n",
    "input_shape = (486,648,3)\n",
    "img_in = Input(shape=input_shape, name='img_in')\n",
    "x = efficientnetb0_preprocess(img_in)\n",
    "x = efficientnetb0(img_in, training=True)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# Classification layer\n",
    "output = Dense(3, activation='softmax', name='dense')(x)\n",
    "# Final model\n",
    "model = Model(inputs=[img_in], outputs=output)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train,y_train,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict([x_train[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference time for EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1, 1944, 2592)"
      ]
     },
     "metadata": {},
     "execution_count": 153
    }
   ],
   "source": [
    "np.expand_dims(x_train[0],axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = []\n",
    "for i in range(0,82):\n",
    "    test = np.expand_dims(x_train[i],axis=0)\n",
    "    tests.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "for i in tqdm(range(0,82)):\n",
    "    model.predict(tests[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "trainable_count = np.sum([K.count_params(w) for w in model.trainable_weights])\n",
    "non_trainable_count = np.sum([K.count_params(w) for w in model.non_trainable_weights])\n",
    "\n",
    "print('Total params: {:,}'.format(trainable_count + non_trainable_count))\n",
    "print('Trainable params: {:,}'.format(trainable_count))\n",
    "print('Non-trainable params: {:,}'.format(non_trainable_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_params(model):\n",
    "    trainable_count = np.sum([K.count_params(w) for w in model.trainable_weights])\n",
    "    non_trainable_count = np.sum([K.count_params(w) for w in model.non_trainable_weights])\n",
    "\n",
    "    print('Total params: {:,}'.format(trainable_count + non_trainable_count))\n",
    "    print('Trainable params: {:,}'.format(trainable_count))\n",
    "    print('Non-trainable params: {:,}'.format(non_trainable_count))\n",
    "    return (trainable_count + non_trainable_count),trainable_count,non_trainable_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_model_params(model)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model_name,model):\n",
    "    model.save(model_name+\".h5\")\n",
    "    print(f\"Model saved as {model_name}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(\"conv1D\",conv1D_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name):\n",
    "    model = tf.keras.models.load_model(model_name)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1D = load_model(\"conv1D.h5\")\n",
    "conv1D.summary()\n",
    "conv1D.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(conv1D.predict(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1D_model = Sequential([\n",
    "    tf.keras.layers.Conv1D(8,(3),input_shape=(1944,2592)),\n",
    "    tf.keras.layers.MaxPool1D(2,2),\n",
    "    tf.keras.layers.Conv1D(16,(3)),\n",
    "    tf.keras.layers.MaxPool1D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(3,activation='softmax')\n",
    "])\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndvi_small_image():\n",
    "    ndvi_img_list = []\n",
    "    for i in range(0,len(image_list)):\n",
    "        img_path = os.path.join(base_path,image_list[i])\n",
    "        ndvi_img = get_ndvi(img_path)\n",
    "        ndvi_img = scale_down(ndvi_img)\n",
    "        ndvi_img_list.append(ndvi_img)\n",
    "    return ndvi_img_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_2D = np.array(ndvi_small_image())\n",
    "x_train_2D = np.expand_dims(x_train_2D,axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(486, 648, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 163
    }
   ],
   "source": [
    "x_train_2D[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "for i in range(0,82):\n",
    "    x_train_i = np.expand_dims(x_train_2D[i],axis=0)\n",
    "    x_train.append(x_train_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1, 486, 648, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 167
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}